{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distracted Driver Detection - This was originally a competition hosted on kaggle.com consisting of a classification problem in computer vision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "SETTING UP DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "d={}\n",
    "with open(\"driver_imgs_list.csv\") as file_obj:\n",
    "    file_data = csv.reader(file_obj)\n",
    "    next(file_data)\n",
    "    for row in file_data:\n",
    "        key = row[1].lower()\n",
    "        if key in d:\n",
    "            d[key].append(row[2])\n",
    "        else:\n",
    "            d[key]=[row[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9']"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_list = list(d.keys())\n",
    "category_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our main Task for Setting Up Data is to -\n",
    "1. Creating Parent Directory as MasterDir and creating 2 Sub Directory Training and Testing \n",
    "2. Creating All category folder/directory for both testing and training Sub-folders\n",
    "3. Copying the Images from imgs/train to MasterDir such that 80% data will go for training and rest for Testing Purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating Parent Directory as MasterDir and creating 2 Sub Directory Training and Testing \n",
    "import os\n",
    "os.mkdir(\"MasterDir\")\n",
    "os.mkdir(\"MasterDir/Training\")\n",
    "os.mkdir(\"MasterDir/Testing\")\n",
    "\n",
    "\n",
    "# Creating All category folder/directory for both testing and training Sub-folders\n",
    "for each in category_list:\n",
    "    os.mkdir(os.path.join(\"MasterDir/Training/\",each))\n",
    "    os.mkdir(os.path.join(\"MasterDir/Testing/\",each))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copying the Images from imgs/train to MasterDir such that 80% data will go for training and rest for Testing Purpose\n",
    "from shutil import copyfile\n",
    "import os\n",
    "split_size = 0.8\n",
    "\n",
    "for category, images in d.items():\n",
    "  train_size = int(split_size*len(images))\n",
    "  train_images = images[:train_size]\n",
    "  test_images = images[train_size:]\n",
    "  for image in train_images:\n",
    "    source = os.path.join('imgs/train/',category,image)\n",
    "    dest = os.path.join('MasterDir/Training/', category, image)\n",
    "    copyfile(source, dest)\n",
    "  for image in test_images:\n",
    "    source = os.path.join('imgs/train/',category, image)\n",
    "    dest = os.path.join('MasterDir/Testing/', category, image)\n",
    "    copyfile(source, dest)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to get Generator file for our model training which will be done with the Help of Keras.ImageDataGenerator Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17934 images belonging to 10 classes.\n",
      "Found 4490 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "training_dir = \"MasterDir/Training/\"\n",
    "testing_dir = \"MasterDir/Testing/\"\n",
    "\n",
    "train_datagen=ImageDataGenerator(rescale=0.1/255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    training_dir,\n",
    "    target_size=(64,64),\n",
    "    class_mode = \"categorical\",\n",
    "    batch_size=128\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=0.1/255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    testing_dir,\n",
    "    target_size=(64,64),\n",
    "    class_mode = \"categorical\",\n",
    "    batch_size=128\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, Here we got 17934 Images with 10 Classes for our Training Data\n",
    "and 4490 images with 10 Classes for Our Testing Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BUILDING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Tensorflow, ImageDataGenerator,CNN_models\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten,Dropout\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_18 (Conv2D)          (None, 62, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 31, 31, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 29, 29, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 14, 14, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 12, 12, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_20 (MaxPoolin  (None, 6, 6, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 4608)              0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 256)               1179904   \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,275,722\n",
      "Trainable params: 1,275,722\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Creating the CNN model\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "\n",
    "# Add Convolutional and Pooling layers\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add fully connected layers\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=Adam(lr=0.01),loss=\"categorical_crossentropy\",metrics=[\"acc\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_acc', patience = 2, min_delta=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\visha\\AppData\\Local\\Temp\\ipykernel_10016\\1505707148.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(train_generator,epochs=10,verbose=1,validation_data=test_generator,callbacks=[es])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "141/141 [==============================] - 124s 877ms/step - loss: 0.6668 - acc: 0.7888 - val_loss: 5.4370 - val_acc: 0.2336\n",
      "Epoch 2/10\n",
      "141/141 [==============================] - 75s 531ms/step - loss: 0.1799 - acc: 0.9478 - val_loss: 5.7073 - val_acc: 0.2367\n",
      "Epoch 3/10\n",
      "141/141 [==============================] - 72s 512ms/step - loss: 0.0951 - acc: 0.9717 - val_loss: 6.8354 - val_acc: 0.2292\n",
      "Epoch 4/10\n",
      "141/141 [==============================] - 71s 504ms/step - loss: 0.0609 - acc: 0.9823 - val_loss: 6.3867 - val_acc: 0.2116\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21f0dedefd0>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator,epochs=10,verbose=1,validation_data=test_generator,callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m image \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mpreprocessing\u001b[39m.\u001b[39mimage\u001b[39m.\u001b[39mload_img(\u001b[39m\"\u001b[39m\u001b[39mimgs/test/img_100407.jpg\u001b[39m\u001b[39m\"\u001b[39m,target_size\u001b[39m=\u001b[39m(\u001b[39m64\u001b[39m,\u001b[39m64\u001b[39m,\u001b[39m3\u001b[39m))\n\u001b[0;32m      3\u001b[0m input_arr \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mpreprocessing\u001b[39m.\u001b[39mimage\u001b[39m.\u001b[39mimg_to_array(image)\n\u001b[0;32m      4\u001b[0m input_arr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([input_arr])  \u001b[39m# Convert single image to a batch.\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "image = tf.keras.preprocessing.image.load_img(\"imgs/test/img_100407.jpg\",target_size=(64,64,3))\n",
    "input_arr = tf.keras.preprocessing.image.img_to_array(image)\n",
    "input_arr = np.array([input_arr])  # Convert single image to a batch.\n",
    "predictions = model.predict(input_arr)\n",
    "for i in range(len(predictions[0])):\n",
    "    if predictions[0][i]==1:\n",
    "        print(category_list[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
